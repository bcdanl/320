<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-0815c480559380816a4d1ea211a47e91.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.7.29">

  <meta name="author" content="Byeong-Hak Choe">
  <meta name="dcterms.date" content="2025-04-07">
  <title>Home – Lecture 10</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-7f9e1a71a62dc5fbf7a8d753f1f01321.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Lecture 10</h1>
  <p class="subtitle">Tree-based Models</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Byeong-Hak Choe 
</div>
<div class="quarto-title-author-email">
<a href="mailto:bchoe@geneseo.edu">bchoe@geneseo.edu</a>
</div>
        <p class="quarto-title-affiliation">
            SUNY Geneseo
          </p>
    </div>
</div>

  <p class="date">April 7, 2025</p>
</section>
<section>
<section id="classification-and-regression-trees" class="title-slide slide level1 center" data-background-color="#1c4982">
<h1><strong>Classification and Regression Trees</strong></h1>

</section>
<section id="decision-tree" class="slide level2">
<h2>Decision Tree</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/tree_rain.png" width="650px">
</p>
<ul>
<li class="fragment">Tree-logic uses a series of steps to come to a conclusion.</li>
<li class="fragment">The trick is to have mini-decisions combine for good choices.</li>
<li class="fragment">Each decision is a node, and the final prediction is a leaf node.</li>
</ul>
</section>
<section id="decision-tree-1" class="slide level2">
<h2>Decision Tree</h2>
<ul>
<li class="fragment">Decision trees partition training data into homogenous nodes/subgroups with similar response values
<ul>
<li class="fragment">Decision trees take any type of data, numerical or categorical.</li>
</ul></li>
<li class="fragment">The subgroups are found recursively using binary partitions
<ul>
<li class="fragment">i.e.&nbsp;asking a series of yes-no questions about the predictor variables</li>
</ul></li>
<li class="fragment">We stop splitting the tree once a stopping criteria has been reached (e.g.&nbsp;maximum depth allowed)</li>
</ul>
</section>
<section id="decision-tree-2" class="slide level2">
<h2>Decision Tree</h2>
<ul>
<li class="fragment">For each subgroup/node, predictions are made with:
<ul>
<li class="fragment"><strong>Classification tree</strong>: the most popular class in the node</li>
<li class="fragment"><strong>Regression tree</strong>: the average of the outcome values in the node</li>
</ul></li>
<li class="fragment"><strong>Classification trees</strong> have class probabilities at the leaves.
<ul>
<li class="fragment">Probability I’ll be in heavy rain is 0.9 (so take an umbrella).</li>
</ul></li>
<li class="fragment"><strong>Regression trees</strong> have a mean outcome at the leaves.
<ul>
<li class="fragment">The expected amount of rain is 2.2 inches (so take an umbrella).</li>
</ul></li>
<li class="fragment">Decision trees make fewer assumptions about the relationship between <code>x</code> and <code>y</code>.
<ul>
<li class="fragment">E.g., linear model assumes the linear relationship between <code>x</code> and <code>y</code>.</li>
</ul></li>
<li class="fragment">Decision trees naturally express certain kinds of interactions among the predictor variables: those of the form: “IF <code>x</code> is true AND <code>y</code> is true, THEN….”</li>
</ul>
</section>
<section id="decision-tree-3" class="slide level2">
<h2>Decision Tree</h2>
<ul>
<li class="fragment">We need a way to estimate the sequence of decisions.
<ul>
<li class="fragment">How many are they?</li>
<li class="fragment">What is the order?</li>
</ul></li>
<li class="fragment">CART grows the tree through a sequence of splits:
<ol type="1">
<li class="fragment">Given any set (node) of data, you can find the optimal split (the error minimizing split) and divide into two child sets.</li>
<li class="fragment">We then look at each child set, and again find the optimal split to divide it into two homogeneous subsets.</li>
<li class="fragment">The children become parents, and we look again for the optimal split on their new children (the grandchildren!).</li>
</ol></li>
<li class="fragment">You stop splitting and growing when the size of the leaf nodes hits some minimum threshold (e.g., say no less than 10 observations per leaf).</li>
</ul>
</section>
<section id="nbc-shows" class="slide level2">
<h2>NBC Shows</h2>
<ul>
<li class="fragment">Data from NBC on response to TV pilots
<ul>
<li class="fragment">Gross Ratings Points (GRP): estimated total viewership, which measures broadcast marketability.</li>
<li class="fragment">Projected Engagement (PE): a more subtle measure of audience.
<ul>
<li class="fragment">After watching a show, viewer is quizzed on order and detail.</li>
<li class="fragment">This measures their engagement with the show (and ads!).</li>
</ul></li>
</ul></li>
</ul>
</section>
<section id="nbc-shows-1" class="slide level2">
<h2>NBC Shows</h2>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-3"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-4"><a></a>nbc <span class="op">=</span> pd.read_csv(<span class="st">"https://bcdanl.github.io/data/nbc_show.csv"</span>)</span>
<span id="cb1-5"><a></a>nbc_demog <span class="op">=</span> pd.read_csv(<span class="st">"https://bcdanl.github.io/data/nbc_demog.csv"</span>)</span>
<span id="cb1-6"><a></a></span>
<span id="cb1-7"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb1-8"><a></a>sns.lmplot(data<span class="op">=</span>nbc, x<span class="op">=</span><span class="st">"GRP"</span>, y<span class="op">=</span><span class="st">"PE"</span>, hue<span class="op">=</span><span class="st">"Genre"</span>, ci<span class="op">=</span><span class="va">None</span>, aspect<span class="op">=</span><span class="fl">1.2</span>, height<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb1-9"><a></a>           markers<span class="op">=</span><span class="st">"o"</span>, scatter_kws<span class="op">=</span>{<span class="st">"s"</span>: <span class="dv">50</span>}, line_kws<span class="op">=</span>{<span class="st">"linewidth"</span>: <span class="dv">2</span>})</span>
<span id="cb1-10"><a></a>plt.title(<span class="st">"Scatter Plot with Linear Fit of GRP vs PE by Genre"</span>)</span>
<span id="cb1-11"><a></a>plt.xlabel(<span class="st">"GRP"</span>)</span>
<span id="cb1-12"><a></a>plt.ylabel(<span class="st">"PE"</span>)</span>
<span id="cb1-13"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="regression-tree-with-nbc-shows" class="slide level2">
<h2>Regression Tree with NBC Shows</h2>
<ul>
<li class="fragment">Consider predicting engagement from <code>GRP</code> and <code>genre</code>.</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, DecisionTreeRegressor, plot_tree</span>
<span id="cb2-2"><a></a></span>
<span id="cb2-3"><a></a><span class="co"># Prepare the predictor set and target variable.</span></span>
<span id="cb2-4"><a></a><span class="co"># We want to model: PE ~ Genre + GRP using all columns except the first.</span></span>
<span id="cb2-5"><a></a><span class="co"># Here, we select the 'Genre' and 'GRP' columns as predictors and 'PE' as the target.</span></span>
<span id="cb2-6"><a></a>X <span class="op">=</span> nbc[[<span class="st">'Genre'</span>, <span class="st">'GRP'</span>]]</span>
<span id="cb2-7"><a></a>y <span class="op">=</span> nbc[<span class="st">'PE'</span>]</span>
<span id="cb2-8"><a></a></span>
<span id="cb2-9"><a></a><span class="co"># If 'Genre' is categorical, convert it to dummy variables.</span></span>
<span id="cb2-10"><a></a><span class="co"># This is necessary because scikit-learn models require numerical inputs.</span></span>
<span id="cb2-11"><a></a>X <span class="op">=</span> pd.get_dummies(X, columns<span class="op">=</span>[<span class="st">'Genre'</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-12"><a></a></span>
<span id="cb2-13"><a></a><span class="co"># Build and fit the regression tree.</span></span>
<span id="cb2-14"><a></a>reg_tree <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">3</span>, min_samples_split<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-15"><a></a>reg_tree.fit(X, y)</span>
<span id="cb2-16"><a></a></span>
<span id="cb2-17"><a></a><span class="co"># Generate predictions for PE and store them in the DataFrame.</span></span>
<span id="cb2-18"><a></a>nbc[<span class="st">'PEpred'</span>] <span class="op">=</span> reg_tree.predict(X)</span>
<span id="cb2-19"><a></a></span>
<span id="cb2-20"><a></a><span class="co"># Plot the regression tree.</span></span>
<span id="cb2-21"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb2-22"><a></a>plot_tree(reg_tree, feature_names<span class="op">=</span>X.columns, filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-23"><a></a>plt.title(<span class="st">"Regression Tree for PE"</span>)</span>
<span id="cb2-24"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="regression-tree-with-nbc-shows-1" class="slide level2">
<h2>Regression Tree with NBC Shows</h2>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>reg_tree <span class="op">=</span> DecisionTreeRegressor(max_depth<span class="op">=</span><span class="dv">3</span>, min_samples_split<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb3-2"><a></a>reg_tree.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li class="fragment"><code>max_depth=3</code>: Limits the tree to 3 levels.
<ul>
<li class="fragment">Helps simplify the model and makes the tree easier to interpret, especially with small datasets.</li>
</ul></li>
<li class="fragment"><code>min_samples_split=2</code>
<ul>
<li class="fragment">Requires at least 2 samples to consider splitting a node.</li>
<li class="fragment">Ensures that the tree can grow even with very few samples in a node.</li>
</ul></li>
<li class="fragment"><code>reg_tree.fit(X, y)</code>
<ul>
<li class="fragment">Trains the regression tree model using predictors <code>X</code> and outcome variable <code>y</code>.</li>
<li class="fragment">The model learns to predict the outcome by finding the best splits based on reducing the sum of squared errors.</li>
</ul></li>
</ul>
</section>
<section id="regression-tree-outcome-explained" class="slide level2">
<h2>Regression Tree Outcome Explained</h2>
<ul>
<li class="fragment"><strong>Squared Error</strong>:
<ul>
<li class="fragment">The sum of squared differences between the actual outcome values and the predicted value (i.e., the mean of those target values) for all samples in the node.<br>
</li>
<li class="fragment">It quantifies the “impurity” or error of the node—the lower the value, the more homogeneous the node is with respect to the outcome variable.</li>
</ul></li>
<li class="fragment"><strong>Samples</strong>:
<ul>
<li class="fragment">The number of observations in the node.<br>
</li>
<li class="fragment">The root node starts with all samples, decreasing with each split.</li>
</ul></li>
</ul>
</section>
<section id="regression-tree-outcome-explained-1" class="slide level2">
<h2>Regression Tree Outcome Explained</h2>
<ul>
<li class="fragment"><strong>Value</strong>:
<ul>
<li class="fragment">In a regression tree, the predicted value for a node is the average of the outcome values for the samples in that node.<br>
</li>
<li class="fragment">The value shown in the node represents this average.</li>
</ul></li>
<li class="fragment"><strong>Leaf Node</strong>:
<ul>
<li class="fragment">A terminal node where no further splitting occurs.<br>
</li>
<li class="fragment">When a new data point falls into that leaf node, the regression tree will predict its output as this value.</li>
</ul></li>
</ul>
</section>
<section id="regression-tree-with-nbc-shows-2" class="slide level2">
<h2>Regression Tree with NBC Shows</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/nbc_linear.png" width="400px"> <!-- <br> --> <!-- <strong>Linear Regression</strong> -->
</p>
</div><div class="column" style="width:50%;">
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/nbc_nonlinear.png" width="375px"> <!-- <br> --> <!-- <strong>Decision Tree</strong> -->
</p>
</div></div>
<ul>
<li class="fragment">Green is comedy, blue is drama, red is reality</li>
<li class="fragment"><strong>Nonlinear</strong>: PE increases with GRP, but in jumps
<ul>
<li class="fragment">Trees automatically learn non-linear response functions and will discover interactions between variables.</li>
</ul></li>
<li class="fragment">Follow how the tree translates into changing the predicted PE.</li>
</ul>
</section>
<section id="classification-tree-with-nbc-shows" class="slide level2">
<h2>Classification Tree with NBC Shows</h2>
<ul>
<li class="fragment">Consider a classification tree to predict genre from demographics.</li>
<li class="fragment">Output from tree shows a series of decision nodes and the proportion in each genre at these nodes, down to the leaves.</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a><span class="co"># Use the demographic variables (excluding the first column) as predictors</span></span>
<span id="cb4-2"><a></a>X <span class="op">=</span> demog.iloc[:, <span class="dv">1</span>:]</span>
<span id="cb4-3"><a></a></span>
<span id="cb4-4"><a></a><span class="co"># Outcome</span></span>
<span id="cb4-5"><a></a>y <span class="op">=</span> nbc[<span class="st">"Genre"</span>]</span>
<span id="cb4-6"><a></a></span>
<span id="cb4-7"><a></a><span class="co"># Build the classification tree. </span></span>
<span id="cb4-8"><a></a>clf <span class="op">=</span> DecisionTreeClassifier(min_samples_split<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb4-9"><a></a>clf.fit(X, y)</span>
<span id="cb4-10"><a></a></span>
<span id="cb4-11"><a></a><span class="co"># Generate predictions for the 'Genre' and store them in the nbc DataFrame</span></span>
<span id="cb4-12"><a></a>nbc[<span class="st">"genrepred"</span>] <span class="op">=</span> clf.predict(X)</span>
<span id="cb4-13"><a></a></span>
<span id="cb4-14"><a></a><span class="co"># Plot the decision tree</span></span>
<span id="cb4-15"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb4-16"><a></a>plot_tree(clf, feature_names<span class="op">=</span>X.columns, class_names<span class="op">=</span>clf.classes_, filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-17"><a></a>plt.title(<span class="st">"Classification Tree for Genre"</span>)</span>
<span id="cb4-18"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="classification-tree-outcome-explained" class="slide level2">
<h2>Classification Tree Outcome Explained</h2>
<p>Each node in the decision tree plot displays key information:</p>
<ul>
<li class="fragment"><strong>Gini</strong>:
<ul>
<li class="fragment">A measure of impurity in the node.</li>
<li class="fragment">Lower values indicate more homogeneous groups.</li>
<li class="fragment">The algorithm tries to minimize this value with each split.</li>
</ul></li>
<li class="fragment"><strong>Value</strong>:
<ul>
<li class="fragment">The distribution of classes (counts) in the node.</li>
<li class="fragment">Helps determine the majority class for prediction.</li>
</ul></li>
<li class="fragment"><strong>Leaf Node</strong>:
<ul>
<li class="fragment">The prediction is made based on the majority class of samples in the node.</li>
</ul></li>
</ul>
</section></section>
<section>
<section id="prunning" class="title-slide slide level1 center" data-background-color="#1c4982">
<h1><strong>Prunning</strong></h1>

</section>
<section id="prunning-1" class="slide level2">
<h2>Prunning</h2>
<ul>
<li class="fragment">The biggest challenge with CART models is avoiding <strong>overfit</strong>.</li>
<li class="fragment">For CART, the usual solution is to rely on <strong>cross validation (CV)</strong>.</li>
<li class="fragment">The way to cross-validate the fully fitted tree is to <strong>prune</strong> it by removing split rules <u>from the bottom up</u>:
<ul>
<li class="fragment">At each step, remove the split that contributes least to deviance reduction.</li>
<li class="fragment">This is a reverse to CART’s growth process.</li>
</ul></li>
<li class="fragment">Pruning yields candidate tree.</li>
<li class="fragment">Each prune step produces a candidate tree model, and we can compare their <strong>out-of-sample prediction performance through CV</strong>.</li>
</ul>
</section>
<section id="boston-housing-data" class="slide level2">
<h2>Boston Housing Data</h2>
<div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a>boston <span class="op">=</span> pd.read_csv(<span class="st">"https://bcdanl.github.io/data/boston.csv"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The <code>boston</code> DataFrame has 506 observations and 14 variables. - per capita income, - environmental factors, - educational facilities, - property size, - crime rate, - etc.</p>
<ul>
<li class="fragment">The goal is to predict housing values (<code>medv</code> in $1,000).</li>
</ul>
</section>
<section id="boston-housing-data-1" class="slide level2">
<h2>Boston Housing Data</h2>
<ul>
<li class="fragment"><code>min_impurity_decrease=0.005</code>: The minimum reduction in impurity required for a split to occur.</li>
<li class="fragment"><strong>Purpose</strong>:
<ul>
<li class="fragment">Ensures that each split meaningfully improves the homogeneity of the node.</li>
<li class="fragment">Prevents splitting when the improvement is too small.</li>
</ul></li>
<li class="fragment"><strong>Effect</strong>:
<ul>
<li class="fragment">Only splits that reduce the impurity by at least 0.005 are allowed.</li>
</ul></li>
<li class="fragment">Do we need all the splits? Is the tree just fitting noise?</li>
</ul>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="co"># Set a random seed for reproducibility</span></span>
<span id="cb6-2"><a></a>np.random.seed(<span class="dv">42120532</span>)</span>
<span id="cb6-3"><a></a>train, test <span class="op">=</span> train_test_split(boston, test_size<span class="op">=</span><span class="fl">0.20</span>, random_state<span class="op">=</span><span class="dv">42120532</span>)</span>
<span id="cb6-4"><a></a>X_train <span class="op">=</span> train.drop(columns<span class="op">=</span>[<span class="st">"medv"</span>])</span>
<span id="cb6-5"><a></a>y_train <span class="op">=</span> train[<span class="st">"medv"</span>]</span>
<span id="cb6-6"><a></a></span>
<span id="cb6-7"><a></a><span class="co"># Without max_depth=3</span></span>
<span id="cb6-8"><a></a>tree_model <span class="op">=</span> DecisionTreeRegressor(min_impurity_decrease<span class="op">=</span><span class="fl">0.005</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb6-9"><a></a>tree_model.fit(X_train, y_train)</span>
<span id="cb6-10"><a></a></span>
<span id="cb6-11"><a></a><span class="co"># Plot the initial regression tree</span></span>
<span id="cb6-12"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">12</span>), dpi<span class="op">=</span><span class="dv">300</span>)</span>
<span id="cb6-13"><a></a>plot_tree(tree_model, feature_names<span class="op">=</span>X_train.columns, filled<span class="op">=</span><span class="va">True</span>, rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-14"><a></a>plt.title(<span class="st">"Regression Tree for medv (Initial Fit)"</span>)</span>
<span id="cb6-15"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="cost-complexity-pruning-path" class="slide level2">
<h2>Cost-Complexity Pruning Path</h2>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a><span class="co"># Obtain the cost-complexity pruning path from the initial tree</span></span>
<span id="cb7-2"><a></a>path <span class="op">=</span> tree_model.cost_complexity_pruning_path(X_train, y_train)  <span class="co"># Get candidate ccp_alpha values and corresponding impurities</span></span>
<span id="cb7-3"><a></a>ccp_alphas <span class="op">=</span> path.ccp_alphas  <span class="co"># Candidate pruning parameters (alpha values)</span></span>
<span id="cb7-4"><a></a>impurities <span class="op">=</span> path.impurities  <span class="co"># Impurity values at each candidate alpha</span></span>
<span id="cb7-5"><a></a></span>
<span id="cb7-6"><a></a><span class="co"># Exclude the maximum alpha value to avoid the trivial tree (a tree with only the root)</span></span>
<span id="cb7-7"><a></a>ccp_alphas <span class="op">=</span> ccp_alphas[:<span class="op">-</span><span class="dv">1</span>]  <span class="co"># Remove the last alpha value which would prune the tree to a single node</span></span>
<span id="cb7-8"><a></a></span>
<span id="cb7-9"><a></a><span class="co"># Set up 10-fold cross-validation</span></span>
<span id="cb7-10"><a></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)  <span class="co"># Initialize 10-fold CV with shuffling and fixed random state</span></span>
<span id="cb7-11"><a></a>cv_scores <span class="op">=</span> []  <span class="co"># List to store mean cross-validated scores (negative MSE)</span></span>
<span id="cb7-12"><a></a>leaf_nodes <span class="op">=</span> []  <span class="co"># List to record the number of leaves for each pruned tree</span></span>
<span id="cb7-13"><a></a></span>
<span id="cb7-14"><a></a><span class="co"># Loop over each candidate alpha value to evaluate its performance</span></span>
<span id="cb7-15"><a></a><span class="cf">for</span> ccp_alpha <span class="kw">in</span> ccp_alphas:</span>
<span id="cb7-16"><a></a>    <span class="co"># Create a DecisionTreeRegressor with the current ccp_alpha and other specified parameters</span></span>
<span id="cb7-17"><a></a>    clf <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb7-18"><a></a>                                ccp_alpha<span class="op">=</span>ccp_alpha,</span>
<span id="cb7-19"><a></a>                                min_impurity_decrease<span class="op">=</span><span class="fl">0.005</span>)</span>
<span id="cb7-20"><a></a>    </span>
<span id="cb7-21"><a></a>    <span class="co"># Perform 10-fold cross-validation and compute negative mean squared error (MSE)</span></span>
<span id="cb7-22"><a></a>    scores <span class="op">=</span> cross_val_score(clf, X_train, y_train,</span>
<span id="cb7-23"><a></a>                             cv<span class="op">=</span>kf, scoring<span class="op">=</span><span class="st">"neg_mean_squared_error"</span>)</span>
<span id="cb7-24"><a></a>    cv_scores.append(np.mean(scores))  <span class="co"># Append the mean CV score for the current alpha</span></span>
<span id="cb7-25"><a></a>    </span>
<span id="cb7-26"><a></a>    <span class="co"># Fit the tree on the training data to record additional metrics</span></span>
<span id="cb7-27"><a></a>    clf.fit(X_train, y_train)</span>
<span id="cb7-28"><a></a>    leaf_nodes.append(clf.get_n_leaves())  <span class="co"># Record the number of leaf nodes in the tree</span></span>
<span id="cb7-29"><a></a></span>
<span id="cb7-30"><a></a><span class="co"># Select the best alpha based on the highest (least negative) mean CV score</span></span>
<span id="cb7-31"><a></a>best_alpha <span class="op">=</span> ccp_alphas[np.argmax(cv_scores)]  <span class="co"># Identify the alpha with the best CV performance</span></span>
<span id="cb7-32"><a></a><span class="bu">print</span>(<span class="st">"Best alpha:"</span>, best_alpha)  <span class="co"># Print the best alpha value</span></span>
<span id="cb7-33"><a></a></span>
<span id="cb7-34"><a></a><span class="co"># Train the final pruned tree using the best alpha found</span></span>
<span id="cb7-35"><a></a>final_tree <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb7-36"><a></a>                                   ccp_alpha<span class="op">=</span>best_alpha,</span>
<span id="cb7-37"><a></a>                                   min_impurity_decrease<span class="op">=</span><span class="fl">0.005</span>)</span>
<span id="cb7-38"><a></a>final_tree.fit(X_train, y_train)  <span class="co"># Fit the final model on the training data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="cost-complexity-pruning-path-1" class="slide level2">
<h2>Cost-Complexity Pruning Path</h2>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>path <span class="op">=</span> tree_model.cost_complexity_pruning_path(X_train, y_train)  <span class="co"># Get candidate ccp_alpha values and corresponding impurities</span></span>
<span id="cb8-2"><a></a>ccp_alphas <span class="op">=</span> path.ccp_alphas  <span class="co"># Candidate pruning parameters (alpha values)</span></span>
<span id="cb8-3"><a></a>impurities <span class="op">=</span> path.impurities  <span class="co"># Impurity values at each candidate alpha</span></span>
<span id="cb8-4"><a></a></span>
<span id="cb8-5"><a></a><span class="co"># Exclude the maximum alpha value to avoid the trivial tree (a tree with only the root)</span></span>
<span id="cb8-6"><a></a>  <span class="co"># Remove the last alpha value which would prune the tree to a single node</span></span>
<span id="cb8-7"><a></a>ccp_alphas <span class="op">=</span> ccp_alphas[:<span class="op">-</span><span class="dv">1</span>]  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li class="fragment">The <code>cost_complexity_pruning_path</code> method computes a series of effective alpha values (<code>ccp_alphas</code>) and the corresponding impurities.</li>
<li class="fragment">These alpha values control the amount of pruning: higher alphas result in simpler (smaller) trees.</li>
</ul>
</section>
<section id="cross-validation-and-metrics-collection" class="slide level2">
<h2>Cross-Validation and Metrics Collection</h2>
<div class="sourceCode" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a></a>kf <span class="op">=</span> KFold(n_splits<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb9-2"><a></a>cv_scores <span class="op">=</span> []  <span class="co"># mean CV scores (negative MSE)</span></span>
<span id="cb9-3"><a></a>leaf_nodes <span class="op">=</span> []</span>
<span id="cb9-4"><a></a>sse <span class="op">=</span> []</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li class="fragment">A 10-fold cross-validation is set up to evaluate each candidate <code>ccp_alpha</code>.</li>
<li class="fragment">We also prepare lists to store:
<ul>
<li class="fragment">Mean CV scores</li>
<li class="fragment">The number of leaf nodes for each pruned tree</li>
<li class="fragment">SSE on training data</li>
</ul></li>
</ul>
</section>
<section id="loop-over-alpha-values" class="slide level2">
<h2>Loop Over Alpha Values</h2>
<ul>
<li class="fragment">For each <code>ccp_alpha</code>, a new tree is built:</li>
<li class="fragment">Cross-validation: cross_val_score computes negative MSE over 10 folds.</li>
<li class="fragment">Leaf Nodes: After fitting, <code>clf.get_n_leaves()</code> records the number of terminal nodes.</li>
<li class="fragment">SSE on Training: SSE is computed by summing squared errors on training data.</li>
</ul>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a><span class="co"># Loop over each candidate alpha value to evaluate its performance</span></span>
<span id="cb10-2"><a></a><span class="cf">for</span> ccp_alpha <span class="kw">in</span> ccp_alphas:</span>
<span id="cb10-3"><a></a>    <span class="co"># Create a DecisionTreeRegressor with the current ccp_alpha and other specified parameters</span></span>
<span id="cb10-4"><a></a>    clf <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb10-5"><a></a>                                ccp_alpha<span class="op">=</span>ccp_alpha,</span>
<span id="cb10-6"><a></a>                                min_impurity_decrease<span class="op">=</span><span class="fl">0.005</span>)</span>
<span id="cb10-7"><a></a>    </span>
<span id="cb10-8"><a></a>    <span class="co"># Perform 10-fold cross-validation and compute negative mean squared error (MSE)</span></span>
<span id="cb10-9"><a></a>    scores <span class="op">=</span> cross_val_score(clf, X_train, y_train,</span>
<span id="cb10-10"><a></a>                             cv<span class="op">=</span>kf, scoring<span class="op">=</span><span class="st">"neg_mean_squared_error"</span>)</span>
<span id="cb10-11"><a></a>    cv_scores.append(np.mean(scores))  <span class="co"># Append the mean CV score for the current alpha</span></span>
<span id="cb10-12"><a></a>    </span>
<span id="cb10-13"><a></a>    <span class="co"># Fit the tree on the training data to record additional metrics</span></span>
<span id="cb10-14"><a></a>    clf.fit(X_train, y_train)</span>
<span id="cb10-15"><a></a>    leaf_nodes.append(clf.get_n_leaves())  <span class="co"># Record the number of leaf nodes in the tree</span></span>
<span id="cb10-16"><a></a></span>
<span id="cb10-17"><a></a>    <span class="co"># Compute SSE (sum of squared errors) on the training set</span></span>
<span id="cb10-18"><a></a>    preds <span class="op">=</span> clf.predict(X_train)  <span class="co"># Predict target values on training data</span></span>
<span id="cb10-19"><a></a>    sse.append(np.<span class="bu">sum</span>((y_train <span class="op">-</span> preds) <span class="op">**</span> <span class="dv">2</span>))  <span class="co"># Calculate and record SSE for training set</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="selecting-and-training-the-final-tree" class="slide level2">
<h2>Selecting and Training the Final Tree</h2>
<div class="sourceCode" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a></a><span class="co"># Select the best alpha based on the highest (least negative) mean CV score</span></span>
<span id="cb11-2"><a></a>best_alpha <span class="op">=</span> ccp_alphas[np.argmax(cv_scores)]  <span class="co"># Identify the alpha with the best CV performance</span></span>
<span id="cb11-3"><a></a><span class="bu">print</span>(<span class="st">"Best alpha:"</span>, best_alpha)  <span class="co"># Print the best alpha value</span></span>
<span id="cb11-4"><a></a></span>
<span id="cb11-5"><a></a><span class="co"># Train the final pruned tree using the best alpha found</span></span>
<span id="cb11-6"><a></a>final_tree <span class="op">=</span> DecisionTreeRegressor(random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb11-7"><a></a>                                   ccp_alpha<span class="op">=</span>best_alpha,</span>
<span id="cb11-8"><a></a>                                   min_impurity_decrease<span class="op">=</span><span class="fl">0.005</span>)</span>
<span id="cb11-9"><a></a>final_tree.fit(X_train, y_train)  <span class="co"># Fit the final model on the training data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li class="fragment"><p>The best alpha is chosen as the one with the highest mean CV score (remember: higher negative MSE means lower error).</p></li>
<li class="fragment"><p>A final tree is trained using the optimal best_alpha, which prunes the tree for better generalization.</p></li>
</ul>
</section>
<section id="cross-validated-tree-pruning" class="slide level2">
<h2>Cross-Validated Tree Pruning</h2>
<p>The algorithm does cross-validation across pruning levels.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a><span class="co"># Plot the average cross-validated MSE against the number of leaf nodes</span></span>
<span id="cb12-2"><a></a>negative_cv_scores <span class="op">=</span> <span class="op">-</span>np.array(cv_scores)</span>
<span id="cb12-3"><a></a></span>
<span id="cb12-4"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb12-5"><a></a>plt.plot(leaf_nodes, negative_cv_scores, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>)</span>
<span id="cb12-6"><a></a>plt.axvline(x<span class="op">=</span>final_tree.get_n_leaves(), color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, label<span class="op">=</span><span class="st">'Leaf Nodes = 21'</span>)  <span class="co"># Add vertical line at 21 leaf nodes</span></span>
<span id="cb12-7"><a></a>plt.xlabel(<span class="st">"Number of Leaf Nodes"</span>)</span>
<span id="cb12-8"><a></a>plt.ylabel(<span class="st">"Mean CV MSE"</span>)</span>
<span id="cb12-9"><a></a>plt.title(<span class="st">"CV Error vs. Number of Leaf Nodes"</span>)</span>
<span id="cb12-10"><a></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb12-11"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="overfitting" class="slide level2">
<h2>Overfitting</h2>
<p>The larger the number of leaf nodes, the smaller SSE on the training data.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a><span class="co"># Plot the SSE on the training against the number of leaf nodes</span></span>
<span id="cb13-2"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>), dpi<span class="op">=</span><span class="dv">150</span>)</span>
<span id="cb13-3"><a></a>plt.plot(leaf_nodes, sse, marker<span class="op">=</span><span class="st">'o'</span>, linestyle<span class="op">=</span><span class="st">'-'</span>)</span>
<span id="cb13-4"><a></a>plt.xlabel(<span class="st">"Number of Leaf Nodes"</span>)</span>
<span id="cb13-5"><a></a>plt.ylabel(<span class="st">"SSE"</span>)</span>
<span id="cb13-6"><a></a>plt.title(<span class="st">"SSE vs. Number of Leaf Nodes"</span>)</span>
<span id="cb13-7"><a></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb13-8"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section></section>
<section>
<section id="random-forest" class="title-slide slide level1 center" data-background-color="#1c4982">
<h1><strong>Random Forest</strong></h1>

</section>
<section id="limitation-of-cart" class="slide level2">
<h2>Limitation of CART</h2>
<ul>
<li class="fragment">CART automatically learns non-linear response functions and will discover interactions between variables.</li>
<li class="fragment">Unfortunately, it is tough to avoid overfit with CART.</li>
<li class="fragment">Real structure of the tree is not easily chosen via cross validation.</li>
<li class="fragment">One way to mitigate the shortcomings of CART is bootstrap aggregation, or <strong>bagging</strong>.</li>
</ul>
</section>
<section id="bootstrap" class="slide level2">
<h2>Bootstrap</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/bootstrap_eg.png" width="900px">
</p>
<ul>
<li class="fragment">Bootstrap is random sampling with replacement.</li>
<li class="fragment">Bootstrap is a reliable tool for uncertainty quantification.</li>
</ul>
</section>
<section id="bagging" class="slide level2">
<h2>Bagging</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/pds_fig10_5.png" width="650px">
</p>
<ul>
<li class="fragment">Real structure that persists across datasets shows up in the average.</li>
<li class="fragment">A bagged ensemble of trees is also less likely to overfit the data.</li>
</ul>
</section>
<section id="random-forest-1" class="slide level2">
<h2>Random Forest</h2>
<div style="display:block; margin:-15px;">

</div>
<ul>
<li class="fragment">Predictions are made the same way as bagging:
<ul>
<li class="fragment"><strong>Regression</strong>: take the <strong>average</strong> across the trees</li>
<li class="fragment"><strong>Classification</strong>: take the <strong>majority vote</strong> across the trees</li>
</ul></li>
<li class="fragment"><strong>Split-variable randomization</strong> adds more randomness to make <strong>each tree more independent of each other</strong></li>
<li class="fragment">Random forest introduces <span class="math inline">\(\texttt{max_features}\)</span> as a tuning parameter:
<ul>
<li class="fragment">It controls the diversity of trees in the ensemble:
<ul>
<li class="fragment">Smaller <span class="math inline">\(\texttt{max_features}\)</span>: More randomness → more diverse trees → potentially better generalization.</li>
<li class="fragment">Larger <span class="math inline">\(\texttt{max_features}\)</span>: Less randomness → trees are more similar → can lead to overfitting/underfitting depending on data.</li>
</ul></li>
<li class="fragment">Typically use <span class="math inline">\(p / 3\)</span> (regression) or <span class="math inline">\(\sqrt{p}\)</span> (classification)</li>
<li class="fragment"><span class="math inline">\(\texttt{max_features} = p\)</span> is <strong>bagging</strong> (use all predictors at every split.)</li>
</ul></li>
</ul>
</section>
<section id="random-forest-2" class="slide level2">
<h2>Random Forest</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/pds_fig10_6_py.png" width="625px">
</p>
<div style="display:block; margin:-20px;">

</div>
<ul>
<li class="fragment">The final ensemble of trees is bagged to make the random forest predictions.</li>
</ul>
</section>
<section id="accuracy-of-the-tree" class="slide level2">
<h2>Accuracy of the Tree</h2>
<ul>
<li class="fragment"><p>For <strong>classification</strong>, accuracy = <span class="math inline">\(\frac{\text{Number of Correct Prediction}}{\text{Total Prediction}}\)</span>.</p></li>
<li class="fragment"><p>For <strong>regression</strong>, accuracy means <span class="math inline">\(R^{2}\)</span>.</p>
<ul>
<li class="fragment"><span class="math inline">\(R^2 = 1\)</span>: model explains all variability</li>
<li class="fragment"><span class="math inline">\(R^2 = 0\)</span>: model explains none of it</li>
</ul></li>
</ul>
</section>
<section id="out-of-bag-samples-for-estimating-the-accuracy" class="slide level2">
<h2>Out-of-bag Samples for Estimating the Accuracy</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/pds_fig10_7.png" width="800px"> <br> <strong>Out-of-bag samples for observation x1</strong>
</p>
<ul>
<li class="fragment">Since <strong>random forest</strong> uses a large number of bootstrap samples, each data point has a corresponding set of <strong>out-of-bag samples</strong>.</li>
</ul>
</section>
<section id="examining-variable-importance" class="slide level2">
<h2>Examining Variable Importance</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/pds_fig10_8.png" width="800px"> <br> <strong>Calculating variable importance of variable v1</strong>
</p>
</section></section>
<section>
<section id="gradient-boosted-trees" class="title-slide slide level1 center" data-background-color="#1c4982">
<h1><strong>Gradient-boosted Trees</strong></h1>

</section>
<section id="gradient-boosted-trees-1" class="slide level2">
<h2>Gradient-boosted Trees</h2>
<ul>
<li class="fragment">Gradient boosting tries to improve prediction performance by sequentially adding trees to an existing ensemble:</li>
</ul>
<ol type="1">
<li class="fragment">Use the current ensemble <span class="math inline">\(TE\)</span> to make predictions on the training data.</li>
<li class="fragment">Measure the residuals between the true outcomes and the predictions on the training data.</li>
<li class="fragment">Fit a new tree <span class="math inline">\(T_i\)</span> to the residuals. Add <span class="math inline">\(T_i\)</span> to the ensemble <span class="math inline">\(TE\)</span>.</li>
<li class="fragment"><strong>Continue until some stopping criteria</strong> to reach final model as a <strong>sum of trees</strong>.</li>
</ol>
<ul>
<li class="fragment">Each model in the sequence <em>slightly</em> improves upon the predictions of the previous models <strong>by focusing on the observations with the largest errors / residuals</strong></li>
</ul>
</section>
<section id="building-up-a-gradient-boosted-tree-model" class="slide level2">
<h2>Building Up a Gradient-Boosted Tree Model</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/pds_fig10_10.png" width="800px"> <br> <strong>Building up a gradient-boosted tree model</strong>
</p>
</section>
<section id="visual-example-of-boosting-in-action" class="slide level2">
<h2>Visual Example of Boosting in Action</h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/boosting-in-action.png" width="800px"> <br> <strong>Boosted regression trees as 0-1024 successive trees are added.</strong>
</p>
</section>
<section id="gradient-boosted-trees-2" class="slide level2">
<h2>Gradient-Boosted Trees</h2>
<p>Update the model parameters in the direction of the loss function (e.g., MSE, deviance)’s descending gradient</p>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/gradient-descent.png" width="800px">
</p>
</section>
<section id="tune-the-learning-rate-in-gradient-descent" class="slide level2">
<h2>Tune the Learning Rate in Gradient Descent</h2>
<p>We need to control how much we update by in each step - <strong>the learning rate</strong></p>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/gradient-descent-learning-rate.png" width="900px">
</p>
</section>
<section id="extreme-gradient-boosting-with-xgboost" class="slide level2">
<h2>eXtreme Gradient Boosting with <a href="https://xgboost.readthedocs.io/">XGBoost</a></h2>
<p align="center">
<img src="https://bcdanl.github.io/lec_figs/deadpool-x.gif" width="800px">
</p>
<ul>
<li class="fragment"><code>XGBoost</code> is one of the most popular open-source library for the gradient boosting algorithm.</li>
</ul>
</section>
<section id="tuning-hyperparameters-with-xgboost" class="slide level2">
<h2>Tuning <strong>hyperparameters</strong> with <a href="https://xgboost.readthedocs.io/">XGBoost</a></h2>
<ul>
<li class="fragment">What we have to consider tuning (our <strong>hyperparameters</strong>):
<ul>
<li class="fragment">number of trees (<code>n_estimators</code>)</li>
<li class="fragment">learning rate (<code>learning_rate</code>), i.e.&nbsp;how much we update in each step</li>
<li class="fragment">these two really have to be tuned together</li>
<li class="fragment">complexity of the trees (<code>max_depth</code>, number of observations in nodes)</li>
<li class="fragment">XGBoost also provides more <strong>regularization</strong> (via <code>gamma</code>) and early stopping</li>
</ul></li>
<li class="fragment"><strong>More work to tune properly as compared to random forests</strong></li>
</ul>


</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<div class="footer footer-default">

</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script>
    document.addEventListener('wheel', function(event) {
        if (event.deltaY > 0) {
            Reveal.next(); // Scroll down to go to the next slide
        } else {
            Reveal.prev(); // Scroll up to go to the previous slide
        }
    }, false);

    window.onload = function() {
        document.querySelectorAll('a').forEach(function(link) {
            link.setAttribute('target', '_blank');
        });
    };

    document.addEventListener('DOMContentLoaded', function() {
      // Query all anchor tags within code blocks (adjust the selector as needed)
      document.querySelectorAll('pre code a').forEach(function(element) {
        element.addEventListener('click', function(e) {
          e.preventDefault(); // Prevent the default anchor action
          e.stopPropagation(); // Stop the event from bubbling up
        });
      });
    });



    document.addEventListener('DOMContentLoaded', function() {
        // Target all span elements within code blocks that have IDs starting with 'cb'
        document.querySelectorAll('pre code span[id^="cb"]').forEach(function(element) {
            element.addEventListener('mouseenter', function() {
                // Apply yellow background color to the hovered span element
                this.style.backgroundColor = '#FFFF99';
            });
            element.addEventListener('mouseleave', function() {
                // Revert the background color when the mouse leaves the span element
                this.style.backgroundColor = '';
            });
        });
    });



    </script>
    
    <script>
      // htmlwidgets need to know to resize themselves when slides are shown/hidden.
      // Fire the "slideenter" event (handled by htmlwidgets.js) when the current
      // slide changes (different for each slide format).
      (function () {
        // dispatch for htmlwidgets
        function fireSlideEnter() {
          const event = window.document.createEvent("Event");
          event.initEvent("slideenter", true, true);
          window.document.dispatchEvent(event);
        }

        function fireSlideChanged(previousSlide, currentSlide) {
          fireSlideEnter();

          // dispatch for shiny
          if (window.jQuery) {
            if (previousSlide) {
              window.jQuery(previousSlide).trigger("hidden");
            }
            if (currentSlide) {
              window.jQuery(currentSlide).trigger("shown");
            }
          }
        }

        // hookup for slidy
        if (window.w3c_slidy) {
          window.w3c_slidy.add_observer(function (slide_num) {
            // slide_num starts at position 1
            fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);
          });
        }

      })();
    </script>

    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
            const codeEl = trigger.previousElementSibling.cloneNode(true);
            for (const childEl of codeEl.children) {
              if (isCodeAnnotation(childEl)) {
                childEl.remove();
              }
            }
            return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
            let selectedAnnoteEl;
            const selectorForAnnotation = ( cell, annotation) => {
              let cellAttr = 'data-code-cell="' + cell + '"';
              let lineAttr = 'data-code-annotation="' +  annotation + '"';
              const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
              return selector;
            }
            const selectCodeLines = (annoteEl) => {
              const doc = window.document;
              const targetCell = annoteEl.getAttribute("data-target-cell");
              const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
              const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
              const lines = annoteSpan.getAttribute("data-code-lines").split(",");
              const lineIds = lines.map((line) => {
                return targetCell + "-" + line;
              })
              let top = null;
              let height = null;
              let parent = null;
              if (lineIds.length > 0) {
                  //compute the position of the single el (top and bottom and make a div)
                  const el = window.document.getElementById(lineIds[0]);
                  top = el.offsetTop;
                  height = el.offsetHeight;
                  parent = el.parentElement.parentElement;
                if (lineIds.length > 1) {
                  const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
                  const bottom = lastEl.offsetTop + lastEl.offsetHeight;
                  height = bottom - top;
                }
                if (top !== null && height !== null && parent !== null) {
                  // cook up a div (if necessary) and position it 
                  let div = window.document.getElementById("code-annotation-line-highlight");
                  if (div === null) {
                    div = window.document.createElement("div");
                    div.setAttribute("id", "code-annotation-line-highlight");
                    div.style.position = 'absolute';
                    parent.appendChild(div);
                  }
                  div.style.top = top - 2 + "px";
                  div.style.height = height + 4 + "px";
                  div.style.left = 0;
                  let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
                  if (gutterDiv === null) {
                    gutterDiv = window.document.createElement("div");
                    gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                    gutterDiv.style.position = 'absolute';
                    const codeCell = window.document.getElementById(targetCell);
                    const gutter = codeCell.querySelector('.code-annotation-gutter');
                    gutter.appendChild(gutterDiv);
                  }
                  gutterDiv.style.top = top - 2 + "px";
                  gutterDiv.style.height = height + 4 + "px";
                }
                selectedAnnoteEl = annoteEl;
              }
            };
            const unselectCodeLines = () => {
              const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
              elementsIds.forEach((elId) => {
                const div = window.document.getElementById(elId);
                if (div) {
                  div.remove();
                }
              });
              selectedAnnoteEl = undefined;
            };
              // Handle positioning of the toggle
          window.addEventListener(
            "resize",
            throttle(() => {
              elRect = undefined;
              if (selectedAnnoteEl) {
                selectCodeLines(selectedAnnoteEl);
              }
            }, 10)
          );
          function throttle(fn, ms) {
          let throttle = false;
          let timer;
            return (...args) => {
              if(!throttle) { // first call gets through
                  fn.apply(this, args);
                  throttle = true;
              } else { // all the others get throttled
                  if(timer) clearTimeout(timer); // cancel #2
                  timer = setTimeout(() => {
                    fn.apply(this, args);
                    timer = throttle = false;
                  }, ms);
              }
            };
          }
            const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
            for (let i=0; i<annoteTargets.length; i++) {
              const annoteTarget = annoteTargets[i];
              const targetCell = annoteTarget.getAttribute("data-target-cell");
              const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
              const contentFn = () => {
                const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
                if (content) {
                  const tipContent = content.cloneNode(true);
                  tipContent.classList.add("code-annotation-tip-content");
                  return tipContent.outerHTML;
                }
              }
              const config = {
                allowHTML: true,
                content: contentFn,
                onShow: (instance) => {
                  selectCodeLines(instance.reference);
                  instance.reference.classList.add('code-annotation-active');
                  window.tippy.hideAll();
                },
                onHide: (instance) => {
                  unselectCodeLines();
                  instance.reference.classList.remove('code-annotation-active');
                },
                maxWidth: 300,
                delay: [50, 0],
                duration: [200, 0],
                offset: [5, 10],
                arrow: true,
                appendTo: function(el) {
                  return el.parentElement.parentElement.parentElement;
                },
                interactive: true,
                interactiveBorder: 10,
                theme: 'light-border',
                placement: 'right',
                popperOptions: {
                  modifiers: [
                  {
                    name: 'flip',
                    options: {
                      flipVariations: false, // true by default
                      allowedAutoPlacements: ['right'],
                      fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
                    },
                  },
                  {
                    name: 'preventOverflow',
                    options: {
                      mainAxis: false,
                      altAxis: false
                    }
                  }
                  ]        
                }      
              };
              window.tippy(annoteTarget, config); 
            }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>